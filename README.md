# Metas

---

## DevOps

### AWS 500 hours

## AWS Certifications
- AWS Certified Solutions Architect – Associate  
  - **Estudio:** Semana 4 - Semana 6 (40 horas/semana)  
- AWS Certified DevOps Engineer – Professional  
  - **Estudio:** Semana 7 - Semana 10 (40 horas/semana)  

---

# AI Career Path

---

## Progress: 2:15/500 hours

### 1. Frameworks y Librerías

#### **Scikit-learn**
- Una librería esencial para modelos tradicionales de Machine Learning.
- Te ayuda a entender conceptos básicos como:
  - Regresión.
  - Clasificación.
  - Clustering.
- Es perfecta para iniciar con los fundamentos de Machine Learning antes de avanzar a Deep Learning.

- 1. Scikit-learn
Enfocado en Machine Learning tradicional: Ideal para modelos simples y eficaces que no requieren redes neuronales profundas.

Casos de uso principales:

Clasificación y regresión:
Modelos como regresión logística, árboles de decisión, SVM, y random forests.
Clustering:
K-means, DBSCAN, y jerárquico.
Reducción de dimensionalidad:
PCA (Análisis de Componentes Principales).
Preprocesamiento de datos:
Normalización, escalado, imputación de valores faltantes.
Selección de modelos y optimización de hiperparámetros:
GridSearchCV, RandomizedSearchCV.
Evaluación de modelos:
Métricas como precisión, recall, AUC-ROC, y matrices de confusión.
¿Cuándo usarlo?

Para prototipos rápidos, análisis exploratorio de datos (EDA), y problemas que no requieren redes neuronales o aprendizaje profundo.

#### **PyTorch**
- Usado extensamente en investigación y desarrollo de modelos de Machine Learning.
- Es más intuitivo para aprendizaje y prototipado rápido.
- Ideal si planeas trabajar en investigación o desarrollo avanzado de IA.

 PyTorch
Enfocado en Deep Learning: Ideal para construir redes neuronales personalizadas y realizar investigación avanzada.

Casos de uso principales:

Investigación en Deep Learning:
Crear redes neuronales completamente personalizadas.
Modelos dinámicos, gracias a su diseño basado en gráficos computacionales dinámicos.
Procesamiento de imágenes:
Redes Convolucionales (CNN) para tareas como clasificación de imágenes, detección de objetos y segmentación.
Procesamiento de texto:
Modelos como transformers (GPT, BERT) para análisis de texto y traducción.
Series temporales:
Modelos recurrentes (RNN, LSTM, GRU) para datos secuenciales.
Aprendizaje por refuerzo:
Entrenamiento de agentes inteligentes para videojuegos, robots, etc.
Investigación avanzada:
Ideal para explorar nuevos algoritmos y técnicas experimentales.
¿Cuándo usarlo?

Si necesitas flexibilidad y control absoluto sobre el diseño de tus modelos.
Perfecto para investigación académica o desarrollo de prototipos de IA.

#### **TensorFlow**
- Ampliamente utilizado en la industria, especialmente para proyectos de producción a gran escala.
- Compatible con Google Cloud y tiene soporte extendido para despliegues en dispositivos móviles e IoT (a través de TensorFlow Lite).
- Si planeas trabajar en aplicaciones de IA comerciales, es una herramienta clave.

3. TensorFlow
Enfocado en Deep Learning y producción a gran escala: Excelente para proyectos de aprendizaje profundo que deben ser escalables y desplegados fácilmente.

Casos de uso principales:

Producción y despliegue:
TensorFlow es el estándar para aplicaciones comerciales, con soporte extendido para producción en la nube, dispositivos móviles (TensorFlow Lite), y navegadores (TensorFlow.js).
Redes neuronales avanzadas:
Soporte para arquitecturas complejas como CNNs, RNNs, y Transformers.
Machine Learning automatizado:
TensorFlow Extended (TFX) para todo el pipeline de ML.
Aprendizaje profundo en escala masiva:
Compatible con TPU (Tensor Processing Units) de Google para entrenar modelos grandes más rápido.
Modelos preentrenados:
TensorFlow Hub ofrece una amplia variedad de modelos preentrenados que pueden usarse fácilmente.
Industria y aplicaciones comerciales:
Uso en vehículos autónomos, IoT, y aplicaciones móviles.
¿Cuándo usarlo?

Cuando necesitas una solución robusta para producción.
Si estás desarrollando una aplicación comercial que requiera despliegue en dispositivos móviles o la nube.

**Recomendación:** 
1. Comienza con **Scikit-learn** para aprender los conceptos básicos de Machine Learning.
2. Luego avanza a **PyTorch** por su facilidad de uso y enfoque en investigación y prototipado.
3. Finalmente, aprende **TensorFlow** para trabajar en aplicaciones comerciales y producción a gran escala.

---

### 2. Fundamentos de Machine Learning y Data Science
#### **Matemáticas para IA**
- Álgebra lineal, cálculo y probabilidad son fundamentales para entender los modelos en profundidad.  
- **Recursos:**  
  - Curso: *Mathematics for Machine Learning* (Coursera).  

#### **Limpieza y análisis de datos**
- Aprende herramientas como:  
  - **Pandas** y **NumPy** para manipulación de datos.  
  - **Matplotlib** y **Seaborn** para visualización de datos.  

---

### 3. Herramientas de Machine Learning
#### **Scikit-learn**
- Una librería esencial para modelos tradicionales de Machine Learning.
- Te ayuda a entender conceptos básicos como:
  - Regresión.  
  - Clasificación.  
  - Clustering.  

---

### 4. Cloud Computing para IA
Con muchas empresas trabajando en la nube, el conocimiento de cómo implementar soluciones en plataformas cloud es vital:

- **Microsoft Azure** (con servicios de IA).  
- **AWS SageMaker** (para entrenar y desplegar modelos en la nube).  
- **Google Cloud AI Platform**.  

---

### 5. Microsoft Certifications

#### **Certificaciones Intermedias**
- **AI-102: Designing and Implementing an Azure AI Solution**: Diseñar, implementar y desplegar soluciones de IA usando servicios como Cognitive Services, Azure Bot Services y Azure Machine Learning.
 
#### **Certificaciones Intermedias**
- **AI Engineer Associate**: Trabaja en soluciones reales y aplica servicios de Azure AI.  
- **Data Scientist Associate (DP-100)**: Foco técnico en desarrollo de modelos.  

#### **Certificaciones Avanzadas (a largo plazo)**
- **Azure Solutions Architect Expert**: Diseñar soluciones integrales en la nube.
- **Data Engineer Associate (DP-203)**: Trabaja con infraestructuras de datos escalables.

---

## Inglés 500 hours
- **Semana 1 (20 horas)**  
  - Speaking: Prácticas conversacionales diarias  
  - Listening: Podcasts y vídeos educativos  
- **Semana 2 (20 horas)**  
  - Writing: Redacción de textos simples y correos  
  - Grammar: Revisión de tiempos verbales comunes  
- **Semana 3 (20 horas)**  
  - Reading: Artículos y libros en inglés técnico  
  - Speaking: Sesiones de práctica avanzadas  

---

## Company
